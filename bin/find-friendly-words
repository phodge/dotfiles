#!/usr/bin/env python3
from subprocess import STDOUT
import tempfile
from subprocess import PIPE
from contextlib import contextmanager
from pathlib import Path
from typing import Iterator, Optional
import json
import os.path
import re
import argparse
import asyncio

PREVIEWLEN = 80


def _handle_arg_word_list_file(
    arg_name: str,
    arg_value: list[str],
    *,
    required: bool,
) -> set[str]:
    if not arg_value:
        if required:
            raise Exception(f'At least one {arg_name} is required')

        return set()

    all_words = set()

    for wlf in arg_value:
        if not os.path.exists(wlf):
            raise Exception(f"Invalid {arg_name}: {wlf}")

        with open(wlf) as f:
            all_words.update(set(f.read().splitlines()))

    return all_words


def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument('--noun', type=str, default="word")
    parser.add_argument('--word-list-file', type=str, action='append')
    parser.add_argument('--state-dir', type=str, required=True)
    parser.add_argument('--word-list-path-var', type=str, required=True)
    parser.add_argument('--known-hostile-file', type=str, action='append')
    parser.add_argument('--known-friendly-file', type=str, action='append')
    parser.add_argument('--command', type=str, action='append', required=True)
    parser.add_argument('--hostile-word', type=str)
    parser.add_argument('--friendly-word', type=str)
    # parser.add_argument('--probably-friendly-file', type=str, action='append')
    # parser.add_argument('--probably-hostile-file', type=str, action='append')
    parser.add_argument('--summary-json', type=str)
    parser.add_argument('--no-verify')
    parser.add_argument('-p', '--parallel', type=int, default=1)
    args = parser.parse_args()

    # check args are set correctly
    if not re.match(r'^[a-zA-Z_]\w*$', args.word_list_path_var):
        raise Exception(f'Invalid word list path var: {args.word_list_path_var}')

    all_words = _handle_arg_word_list_file(
        '--word-list-file',
        args.word_list_file,
        required=True,
    )
    known_hostile = _handle_arg_word_list_file(
        '--known-hostile-file',
        args.known_hostile_file,
        required=False,
    )
    known_friendly = _handle_arg_word_list_file(
        '--known-friendly-file',
        args.known_friendly_file,
        required=False,
    )

    if not os.path.exists(args.state_dir):
        raise Exception(f"--state-dir folder {args.state_dir} does not exist")

    strategy = Strategy1(
        noun=args.noun,
        all_words=all_words,
        state_dir=Path(args.state_dir),
        path_var=args.word_list_path_var,
        known_hostile=known_hostile,
        known_friendly=known_friendly,
        commands=list(args.command),
        hostile_word=args.hostile_word,
        friendly_word=args.friendly_word,
    )

    if not args.no_verify:
        asyncio.run(strategy.verify_commands())

    summary = asyncio.run(strategy.execute(parallel=args.parallel))
    if args.summary_json:
        summary_str = json.dumps(summary, indent=2, sort_keys=True)
        with open(args.summary_json, 'w') as f:
            f.write(summary_str)


class Strategy:
    _noun: str
    _all_words: set[str]
    _path_var: str
    _commands: list[str]
    _state_dir: Path
    _proven_hostile: set[str]
    _proven_friendly: set[str]

    def __init__(
        self,
        noun: str,
        all_words: set[str],
        path_var: str,
        known_hostile: set[str],
        known_friendly: set[str],
        commands: list[str],
        state_dir: Path,
        hostile_word: str,
        friendly_word: str,
    ) -> None:
        self._noun = noun
        self._all_words = all_words
        self._path_var = path_var
        self._commands = commands

        self._state_dir = state_dir
        self._hostile_word = hostile_word
        self._friendly_word = friendly_word
        self._hostile_filename = f'{hostile_word}.txt'
        self._friendly_filename = f'{friendly_word}.txt'

        # first step is to add known friendly and hostile words to state dir
        self._safely_add_friendly_words(state_dir, known_friendly)
        self._safely_add_hostile_words(state_dir, known_hostile)

        # find out what words have already been checked (in case we restart the process)
        self._proven_hostile = set(_read_words_from_file(state_dir / self._hostile_filename))
        self._proven_friendly = set(_read_words_from_file(state_dir / self._friendly_filename))

    def _safely_add_friendly_words(self, statedir: Path, words: set[str]) -> None:
        _safely_add_words_to_file(statedir / self._friendly_filename, words)

    def _safely_add_hostile_words(self, statedir: Path, words: set[str]) -> None:
        _safely_add_words_to_file(statedir / self._hostile_filename, words)

    @contextmanager
    def _makeTempStateDir(self, *, extra_friendly: set[str]) -> Iterator[Path]:
        # create a temporary folder for the custom word list
        hostile_words = set(self._proven_hostile)
        friendly_words = set(self._proven_friendly)
        friendly_words.update(extra_friendly)

        with tempfile.TemporaryDirectory() as tmpdir:
            self._safely_add_friendly_words(Path(tmpdir), friendly_words)
            self._safely_add_hostile_words(Path(tmpdir), hostile_words)
            yield Path(tmpdir)

    def get_next_job(self) -> Iterator[asyncio.Task]:
        raise NotImplementedError

    async def execute(self, parallel: int) -> dict[str, str | int]:
        # our job is to keep N parallel tasks going at once and begin a new one
        # whenever one finishes
        active_tasks = []
        tasks_completed = 0
        for job in self.get_next_job():
            active_tasks.append(job)
            tasks_completed += 1

            if len(active_tasks) >= parallel:
                # wait for a job to complete before continuing
                _, pending = await asyncio.wait(
                    active_tasks,
                    return_when=asyncio.FIRST_COMPLETED,
                )
                active_tasks = list(pending)

        # wait for remaining tasks to complete
        for task in active_tasks:
            await task

        await self.run_final_job()

        # return a summary of what happened
        return {"tasks_completed": tasks_completed}

    async def verify_commands(self) -> None:
        already_done_friendly = set(_read_words_from_file(self._state_dir / self._friendly_filename))

        # create a temporary dir to verify with current word list. Note that
        # this directory can't be cleaned up until the jobs are cleaned up.
        with self._makeTempStateDir(extra_friendly=already_done_friendly) as tmpdir:
            jobs: list[asyncio.Task] = []

            # first create jobs to verify in isolation
            for commandstr in self._commands:
                jobs.append(asyncio.create_task(self._verify_command(commandstr, None)))

            # now create jobs that verify with the current word list
            for commandstr in self._commands:
                jobs.append(asyncio.create_task(self._verify_command(commandstr, tmpdir)))

            for job in jobs:
                outcome = await job
                if outcome is not None:
                    raise Exception("ERROR: " + outcome)

        print("All commands are working")

    async def _verify_command(self, commandstr: str, state_dir: Optional[Path]) -> Optional[str]:
        if len(commandstr) >= PREVIEWLEN:
            preview = commandstr[:(PREVIEWLEN - 3)] + '...'
        else:
            preview = commandstr
        verifywhat = f"command '{preview}'"
        if state_dir:
            verifywhat += f" with current {self._noun} list"
        else:
            verifywhat += " in isolation"

        print(f"Verifying {verifywhat}")
        env = os.environ.copy()
        if state_dir:
            env[self._path_var] = str(state_dir / self._friendly_filename)
        else:
            env[self._path_var] = '/dev/null'

        proc = await asyncio.create_subprocess_exec(
            'bash', '-c', commandstr,
            env=env,
            stdout=PIPE,
            stderr=STDOUT,
        )
        stdout, _ = await proc.communicate()

        if proc.returncode is None:
            raise Exception("Impossible")

        if proc.returncode > 0:
            print(stdout)
            return f"Verification failed for {verifywhat}"

        # no failure
        return None

    async def run_final_job(self) -> None:
        """Placeholder for any final cleanup the strategy might need to execute."""


class Strategy1(Strategy):
    """
    Given words A, B, C, D, etc and commands $1, $2, $3 etc, and maximum
    concurrent processes of N, start a parallel job for up to N words at a
    time. Test each word's commands one by one and if they all succeed, add
    them to the friendly.txt. If any of the commands fails, add the word to
    hostile.txt.

    This strategy has two weaknesses:
    - can only test N words at a time in parallel.
    - can easily produce a non-working word lists where there are two
      interdependent words. For example, if A or B can be friendly, but not
      both, but they are tested in separate parallel processes, they  might
      both get switched off at the same time.
    - won't discover a scenario where A and B are both friendly, but they must
      be made friendly together.
    """
    def __init__(self, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self._postponed_friendly: set[str] = set()

    def get_next_job(self) -> Iterator[asyncio.Task]:
        words_to_check = sorted(self._all_words.difference([
            *self._proven_hostile,
            *self._proven_friendly,
        ]))
        print(f"{len(words_to_check)} words left to check ...")

        for word in sorted(words_to_check):
            yield asyncio.create_task(self._check_words_and_add_to_word_list({word}, can_mark_hostile=True))

    async def run_final_job(self) -> None:
        print(f"Rechecking {len(self._postponed_friendly)} postponed {self._noun}(s) ...")
        postponed_words = list(sorted(self._postponed_friendly))
        batches: list[list[str]] = [postponed_words]
        while len(batches):
            batch = batches[0]
            batches = batches[1:]
            outcome = await self._check_words_and_add_to_word_list(
                set(batch),
                can_mark_hostile=len(batch) == 1,
            )
            if outcome == "__friendly__":
                # all words were marked friendly, go to next batch
                continue

            assert outcome == "__hostile__"
            if len(batch) == 1:
                # the word will already have been marked hostile
                continue

            # split the batch and add to the front of the queue
            halfway = len(batch) // 2
            batches = [
                batch[0:halfway],
                batch[halfway:],
                *batches,
            ]

    async def _check_words_and_add_to_word_list(
        self,
        words: set[str],
        can_mark_hostile: bool,
    ) -> str:
        wordstr = "+".join(sorted(words))
        noun = self._noun
        if (len(words) > 1) and not noun.endswith('s'):
            noun = f"{noun}s"

        word_list_before_start = set(self._proven_friendly)

        # create a temporary dir with the custom word lists
        all_succeeded = True
        with self._makeTempStateDir(extra_friendly=words) as tmpdir:
            # TODO: eventually we want to run commands in parallel, however
            # this isn't a big deal for now because my current use case only
            # has one command to check in real-world use
            for commandstr in self._commands:
                env = os.environ.copy()
                env[self._path_var] = str(tmpdir / self._friendly_filename)
                if len(commandstr) >= PREVIEWLEN:
                    preview = commandstr[:(PREVIEWLEN - 3)] + '...'
                else:
                    preview = commandstr
                print(f"Checking {noun} {wordstr} with '{preview}'")
                proc = await asyncio.create_subprocess_exec(
                    'bash', '-c', commandstr,
                    env=env,
                    stdout=PIPE,
                    stderr=STDOUT,
                )
                stdout, stderr = await proc.communicate()

                if proc.returncode is None:
                    raise Exception("Impossible")

                if proc.returncode > 0:
                    print(f"A command failed for {noun} {wordstr}")
                    all_succeeded = False
                    break

        if all_succeeded:
            # if the list of friendly words has changed, we'll have to recheck this word later
            if self._proven_friendly != word_list_before_start:
                print(f"Word list changed while checking {noun} {wordstr} - will recheck later")
                self._postponed_friendly.update(words)
                return "__postpone__"

            self._proven_friendly.update(words)
            print(f"All commands succeeded when {noun} {wordstr} was marked friendly")
            self._safely_add_friendly_words(self._state_dir, words)
            return "__friendly__"

        # at least one word is hostile
        print(f"{noun} {wordstr} is {self._hostile_word} - some commands fail when it is marked friendly")
        if can_mark_hostile:
            self._proven_hostile.update(words)
            self._safely_add_hostile_words(self._state_dir, words)
        return "__hostile__"


def _safely_add_words_to_file(
    filepath: Path,
    words: set[str],
) -> None:
    lockfile = (filepath.parent / (filepath.name + '.lock'))
    backupfile = (filepath.parent / (filepath.name + '.prev'))

    # create the lock file
    with open(lockfile, 'x') as f:
        # read any existing file
        if filepath.exists():
            existing = _read_words_from_file(filepath)
        else:
            existing = []

        seen = set()
        for word in existing:
            if not word:
                continue

            if word in seen:
                continue

            seen.add(word)
            f.write(word + "\n")

        # now add the new words
        for word in sorted(words):
            if word in seen:
                continue

            f.write(word + "\n")

        # if there is an existing file, move it to backup spot
        if filepath.exists():
            filepath.rename(backupfile)

    # move lockfile to final file path to release the lock
    lockfile.rename(filepath)


def _read_words_from_file(filepath: Path) -> list[str]:
    if not filepath.exists():
        return []

    return [
        word.strip()
        for word in filepath.read_text().splitlines()
        if word.strip()
    ]


if __name__ == '__main__':
    main()
